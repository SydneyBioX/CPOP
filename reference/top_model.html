<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>All three steps of TOP modelling — top_model • top</title>

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="All three steps of TOP modelling — top_model" />

<meta property="og:description" content="All three steps of TOP modelling" />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">top</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.8</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/top.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>All three steps of TOP modelling</h1>
    
    <div class="hidden name"><code>top_model.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>All three steps of TOP modelling</p>
    
    </div>

    <pre class="usage"><span class='fu'>top_model</span>(<span class='no'>z1</span>, <span class='no'>z2</span>, <span class='no'>y1</span>, <span class='no'>y2</span>, <span class='no'>w</span>, <span class='kw'>nIter</span> <span class='kw'>=</span> <span class='fl'>20</span>, <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>s</span> <span class='kw'>=</span> <span class='st'>"lambda.min"</span>,
  <span class='no'>...</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>z1</th>
      <td><p>A data matrix</p></td>
    </tr>
    <tr>
      <th>z2</th>
      <td><p>A data matrix</p></td>
    </tr>
    <tr>
      <th>y1</th>
      <td><p>A vector</p></td>
    </tr>
    <tr>
      <th>y2</th>
      <td><p>A vector</p></td>
    </tr>
    <tr>
      <th>w</th>
      <td><p>A vector</p></td>
    </tr>
    <tr>
      <th>nIter</th>
      <td><p>Number of iterations</p></td>
    </tr>
    <tr>
      <th>alpha</th>
      <td><p>Lasso alpha</p></td>
    </tr>
    <tr>
      <th>s</th>
      <td><p>CV-Lasso lambda</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>Extra parameter settings for cv.glmnet in top1</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A vector</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/Random'>set.seed</a></span>(<span class='fl'>1</span>)
<span class='no'>n</span> <span class='kw'>=</span> <span class='fl'>1000</span>
<span class='no'>p</span> <span class='kw'>=</span> <span class='fl'>10</span>
<span class='no'>x1</span> <span class='kw'>=</span> <span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/matrix'>matrix</a></span>(<span class='fu'><a href='https://www.rdocumentation.org/packages/stats/topics/Normal'>rnorm</a></span>(<span class='no'>n</span> * <span class='no'>p</span>, <span class='kw'>mean</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>sd</span> <span class='kw'>=</span> <span class='fl'>1</span>), <span class='kw'>nrow</span> <span class='kw'>=</span> <span class='no'>n</span>, <span class='kw'>ncol</span> <span class='kw'>=</span> <span class='no'>p</span>)
<span class='no'>x2</span> <span class='kw'>=</span> <span class='no'>x1</span> + <span class='fl'>0.1</span>
<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/colnames'>colnames</a></span>(<span class='no'>x1</span>) <span class='kw'>=</span> <span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/colnames'>colnames</a></span>(<span class='no'>x2</span>) <span class='kw'>=</span> <span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/paste'>paste0</a></span>(<span class='st'>"X"</span>, <span class='fl'>1</span>:<span class='no'>p</span>)
<span class='no'>k</span> <span class='kw'>=</span> <span class='fl'>2</span>
<span class='no'>beta</span> <span class='kw'>=</span> <span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/c'>c</a></span>(<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/rep'>rep</a></span>(<span class='fl'>1</span>, <span class='no'>k</span>), <span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/rep'>rep</a></span>(<span class='fl'>0</span>, <span class='no'>p</span> - <span class='no'>k</span>))
<span class='no'>expit</span> <span class='kw'>=</span> <span class='kw'>function</span>(<span class='no'>x</span>) <span class='fl'>1</span>/(<span class='fl'>1</span>+<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/Log'>exp</a></span>(-<span class='no'>x</span>))
<span class='no'>y1</span> <span class='kw'>=</span> <span class='fu'><a href='https://www.rdocumentation.org/packages/stats/topics/Binomial'>rbinom</a></span>(<span class='no'>n</span>, <span class='fl'>1</span>, <span class='kw'>prob</span> <span class='kw'>=</span> <span class='fu'>expit</span>(<span class='no'>x1</span> <span class='kw'>%*%</span> <span class='no'>beta</span>))
<span class='no'>y2</span> <span class='kw'>=</span> <span class='fu'><a href='https://www.rdocumentation.org/packages/stats/topics/Binomial'>rbinom</a></span>(<span class='no'>n</span>, <span class='fl'>1</span>, <span class='kw'>prob</span> <span class='kw'>=</span> <span class='fu'>expit</span>(<span class='no'>x2</span> <span class='kw'>%*%</span> <span class='no'>beta</span>))
<span class='no'>z1</span> <span class='kw'>=</span> <span class='fu'><a href='pairwise_col_diff.html'>pairwise_col_diff</a></span>(<span class='no'>x1</span>)
<span class='no'>z2</span> <span class='kw'>=</span> <span class='fu'><a href='pairwise_col_diff.html'>pairwise_col_diff</a></span>(<span class='no'>x2</span>)
<span class='no'>w</span> <span class='kw'>=</span> <span class='fu'><a href='compute_weights.html'>compute_weights</a></span>(<span class='no'>z1</span>, <span class='no'>z2</span>)
<span class='no'>nIter</span> <span class='kw'>=</span> <span class='fl'>20</span>
<span class='fu'>top_model</span>(<span class='no'>z1</span>, <span class='no'>z2</span>, <span class='no'>y1</span>, <span class='no'>y2</span>, <span class='no'>w</span>, <span class='kw'>nIter</span> <span class='kw'>=</span> <span class='fl'>20</span>, <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>s</span> <span class='kw'>=</span> <span class='st'>"lambda.min"</span>)</div><div class='output co'>#&gt; <span class='message'>Step 01: Number of selected features: 14 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 02: Number of selected features: 23 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 03: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 04: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 05: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 06: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 07: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 08: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 09: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 10: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 11: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 12: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 13: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 14: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 15: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 16: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 17: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 18: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 19: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 20: Number of selected features: 35 out of 45</span></div><div class='output co'>#&gt; <span class='message'>Step 01: Number of leftover features: 29 out of 35</span></div><div class='output co'>#&gt; <span class='message'>The sign matrix between the two data:</span></div><div class='output co'>#&gt;     
#&gt;      -1 0 1
#&gt;   -1  0 0 3
#&gt;   0   0 0 0
#&gt;   1   3 0 0</div><div class='output co'>#&gt; <span class='message'>Step 02: Number of leftover features: 26 out of 35</span></div><div class='output co'>#&gt; <span class='message'>The sign matrix between the two data:</span></div><div class='output co'>#&gt;     
#&gt;      -1 0 1
#&gt;   -1  0 0 1
#&gt;   0   0 0 0
#&gt;   1   2 0 0</div><div class='output co'>#&gt; <span class='message'>Step 03: Number of leftover features: 25 out of 35</span></div><div class='output co'>#&gt; <span class='message'>The sign matrix between the two data:</span></div><div class='output co'>#&gt;     
#&gt;      -1 0 1
#&gt;   -1  0 0 1
#&gt;   0   0 0 0
#&gt;   1   0 0 0</div><div class='output co'>#&gt; <span class='message'>Step 04: Number of leftover features: 25 out of 35</span></div><div class='output co'>#&gt; <span class='message'>The sign matrix between the two data:</span></div><div class='output co'>#&gt;     
#&gt;      -1 0 1
#&gt;   -1  0 0 0
#&gt;   0   0 0 0
#&gt;   1   0 0 0</div><div class='output co'>#&gt; $en1
#&gt; $lambda
#&gt;   [1] 144.24621777 131.43178135 119.75574415 109.11697391  99.42332269
#&gt;   [6]  90.59082873  82.54298920  75.21009754  68.52863977  62.44074429
#&gt;  [11]  56.89368067  51.83940289  47.23413321  43.03798300  39.21460722
#&gt;  [16]  35.73088959  32.55665584  29.66441227  27.02910765  24.62791622
#&gt;  [21]  22.44004002  20.44652872  18.63011546  16.97506735  15.46704915
#&gt;  [26]  14.09299914  12.84101594  11.70025547  10.66083702   9.71375765
#&gt;  [31]   8.85081419   8.06453225   7.34810143   6.69531636   6.10052290
#&gt;  [36]   5.55856926   5.06476129   4.61482186   4.20485380   3.83130618
#&gt;  [41]   3.49094350   3.18081770   2.89824262   2.64077074   2.40617194
#&gt;  [46]   2.19241426   1.99764622   1.82018083   1.65848099   1.51114611
#&gt;  [51]   1.37690005   1.25458005   1.14312661   1.04157439   0.94904380
#&gt;  [56]   0.86473336   0.78791283   0.71791683   0.65413908   0.59602716
#&gt;  [61]   0.54307775   0.49483222   0.45087269   0.41081840   0.37432243
#&gt;  [66]   0.34106866   0.31076906   0.28316119   0.25800593   0.23508540
#&gt;  [71]   0.21420106   0.19517203   0.17783348   0.16203524   0.14764048
#&gt;  [76]   0.13452451   0.12257372   0.11168461   0.10176286   0.09272252
#&gt;  [81]   0.08448531   0.07697987   0.07014119   0.06391004   0.05823245
#&gt;  [86]   0.05305924   0.04834560   0.04405071   0.04013737   0.03657167
#&gt;  [91]   0.03332275   0.03036245   0.02766513   0.02520744   0.02296808
#&gt;  [96]   0.02092766   0.01906850   0.01737451   0.01583100   0.01442462
#&gt; 
#&gt; $cvm
#&gt;   [1] 1.385952 1.383205 1.382709 1.382276 1.381801 1.381281 1.380714 1.380093
#&gt;   [9] 1.379415 1.378674 1.377865 1.376983 1.376021 1.374973 1.373831 1.372588
#&gt;  [17] 1.371237 1.369769 1.368175 1.366447 1.364589 1.362596 1.360418 1.358067
#&gt;  [25] 1.355536 1.352816 1.349896 1.346769 1.343428 1.339865 1.336076 1.332055
#&gt;  [33] 1.327802 1.323315 1.318596 1.313650 1.308484 1.303107 1.297532 1.291773
#&gt;  [41] 1.285850 1.279782 1.273593 1.267309 1.260957 1.254565 1.248163 1.241781
#&gt;  [49] 1.235449 1.229197 1.223053 1.217044 1.211196 1.205532 1.200073 1.194836
#&gt;  [57] 1.189838 1.185091 1.180604 1.176384 1.172436 1.168760 1.165355 1.162219
#&gt;  [65] 1.159344 1.156724 1.154349 1.152209 1.150293 1.148587 1.147078 1.145753
#&gt;  [73] 1.144598 1.143598 1.142741 1.142013 1.141401 1.140893 1.140477 1.140142
#&gt;  [81] 1.139877 1.139674 1.139523 1.139418 1.139350 1.139314 1.139304 1.139315
#&gt;  [89] 1.139344 1.139385 1.139437 1.139496 1.139560 1.139628 1.139698 1.139768
#&gt;  [97] 1.139838 1.139906 1.139971 1.139980
#&gt; 
#&gt; $cvsd
#&gt;   [1] 0.0006396569 0.0005842488 0.0005621842 0.0005676987 0.0005743653
#&gt;   [6] 0.0005823830 0.0005919849 0.0006034335 0.0006170209 0.0006330693
#&gt;  [11] 0.0006519290 0.0006739768 0.0006996130 0.0007292579 0.0007633484
#&gt;  [16] 0.0008023344 0.0008466766 0.0008968437 0.0009533118 0.0010165639
#&gt;  [21] 0.0010878997 0.0011635656 0.0012494992 0.0013443749 0.0014484783
#&gt;  [26] 0.0015623246 0.0016864309 0.0018213126 0.0019674788 0.0021254256
#&gt;  [31] 0.0022956293 0.0024785374 0.0026745601 0.0028840601 0.0031073423
#&gt;  [36] 0.0033446438 0.0035961237 0.0038618544 0.0041418133 0.0044358762
#&gt;  [41] 0.0047438133 0.0050652846 0.0053998471 0.0057469496 0.0061059408
#&gt;  [46] 0.0064760771 0.0068565315 0.0072464040 0.0076447334 0.0080505091
#&gt;  [51] 0.0084626835 0.0088801836 0.0093019215 0.0097268042 0.0101537424
#&gt;  [56] 0.0105816580 0.0110094897 0.0114361991 0.0118607744 0.0122822345
#&gt;  [61] 0.0126996323 0.0131120572 0.0135186384 0.0139185466 0.0143109966
#&gt;  [66] 0.0146952496 0.0150706167 0.0154364300 0.0157919204 0.0161368605
#&gt;  [71] 0.0164706774 0.0167929640 0.0171033817 0.0174016576 0.0176875851
#&gt;  [76] 0.0179610256 0.0182219080 0.0184702290 0.0187060512 0.0189295005
#&gt;  [81] 0.0191407620 0.0193400750 0.0195277272 0.0197040482 0.0198694041
#&gt;  [86] 0.0200241900 0.0201687071 0.0203039442 0.0204298381 0.0205467388
#&gt;  [91] 0.0206552189 0.0207557964 0.0208489389 0.0209350916 0.0210145621
#&gt;  [96] 0.0210878773 0.0211554893 0.0212179289 0.0212753388 0.0212926651
#&gt; 
#&gt; $cvup
#&gt;   [1] 1.386592 1.383790 1.383272 1.382843 1.382375 1.381864 1.381305 1.380696
#&gt;   [9] 1.380032 1.379307 1.378517 1.377657 1.376721 1.375702 1.374594 1.373391
#&gt;  [17] 1.372084 1.370666 1.369129 1.367464 1.365677 1.363760 1.361667 1.359412
#&gt;  [25] 1.356985 1.354378 1.351582 1.348591 1.345395 1.341991 1.338371 1.334534
#&gt;  [33] 1.330476 1.326199 1.321704 1.316995 1.312080 1.306969 1.301673 1.296209
#&gt;  [41] 1.290593 1.284847 1.278993 1.273056 1.267063 1.261041 1.255020 1.249027
#&gt;  [49] 1.243094 1.237247 1.231516 1.225924 1.220498 1.215259 1.210227 1.205418
#&gt;  [57] 1.200848 1.196527 1.192465 1.188667 1.185136 1.181872 1.178874 1.176137
#&gt;  [65] 1.173655 1.171419 1.169419 1.167646 1.166084 1.164723 1.163549 1.162546
#&gt;  [73] 1.161701 1.161000 1.160429 1.159974 1.159623 1.159363 1.159183 1.159071
#&gt;  [81] 1.159018 1.159014 1.159051 1.159122 1.159219 1.159338 1.159473 1.159619
#&gt;  [89] 1.159774 1.159932 1.160092 1.160252 1.160409 1.160563 1.160712 1.160856
#&gt;  [97] 1.160993 1.161124 1.161247 1.161273
#&gt; 
#&gt; $cvlo
#&gt;   [1] 1.385313 1.382621 1.382147 1.381708 1.381226 1.380699 1.380122 1.379489
#&gt;   [9] 1.378798 1.378041 1.377213 1.376309 1.375322 1.374243 1.373068 1.371786
#&gt;  [17] 1.370390 1.368872 1.367222 1.365431 1.363501 1.361433 1.359168 1.356723
#&gt;  [25] 1.354088 1.351253 1.348210 1.344948 1.341460 1.337740 1.333780 1.329577
#&gt;  [33] 1.325127 1.320431 1.315489 1.310306 1.304888 1.299245 1.293390 1.287337
#&gt;  [41] 1.281106 1.274717 1.268194 1.261562 1.254851 1.248089 1.241307 1.234535
#&gt;  [49] 1.227804 1.221146 1.214590 1.208164 1.201894 1.195805 1.189919 1.184255
#&gt;  [57] 1.178829 1.173655 1.168743 1.164102 1.159736 1.155648 1.151837 1.148300
#&gt;  [65] 1.145033 1.142028 1.139278 1.136773 1.134501 1.132450 1.130607 1.128960
#&gt;  [73] 1.127494 1.126197 1.125054 1.124052 1.123180 1.122423 1.121771 1.121212
#&gt;  [81] 1.120736 1.120334 1.119996 1.119714 1.119481 1.119290 1.119135 1.119011
#&gt;  [89] 1.118914 1.118839 1.118782 1.118740 1.118711 1.118693 1.118683 1.118680
#&gt;  [97] 1.118682 1.118688 1.118696 1.118687
#&gt; 
#&gt; $nzero
#&gt;  s0  s1  s2  s3  s4  s5  s6  s7  s8  s9 s10 s11 s12 s13 s14 s15 s16 s17 s18 s19 
#&gt;  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25 
#&gt; s20 s21 s22 s23 s24 s25 s26 s27 s28 s29 s30 s31 s32 s33 s34 s35 s36 s37 s38 s39 
#&gt;  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25 
#&gt; s40 s41 s42 s43 s44 s45 s46 s47 s48 s49 s50 s51 s52 s53 s54 s55 s56 s57 s58 s59 
#&gt;  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25 
#&gt; s60 s61 s62 s63 s64 s65 s66 s67 s68 s69 s70 s71 s72 s73 s74 s75 s76 s77 s78 s79 
#&gt;  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25 
#&gt; s80 s81 s82 s83 s84 s85 s86 s87 s88 s89 s90 s91 s92 s93 s94 s95 s96 s97 s98 s99 
#&gt;  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25 
#&gt; 
#&gt; $name
#&gt;            deviance 
#&gt; "Binomial Deviance" 
#&gt; 
#&gt; $glmnet.fit
#&gt; 
#&gt; Call:  glmnet(x = z1[, top2_result], y = y1, family = "binomial", alpha = 0) 
#&gt; 
#&gt;        Df       %Dev    Lambda
#&gt;   [1,] 25 -2.403e-15 144.20000
#&gt;   [2,] 25  3.051e-03 131.40000
#&gt;   [3,] 25  3.345e-03 119.80000
#&gt;   [4,] 25  3.666e-03 109.10000
#&gt;   [5,] 25  4.017e-03  99.42000
#&gt;   [6,] 25  4.401e-03  90.59000
#&gt;   [7,] 25  4.821e-03  82.54000
#&gt;   [8,] 25  5.280e-03  75.21000
#&gt;   [9,] 25  5.782e-03  68.53000
#&gt;  [10,] 25  6.329e-03  62.44000
#&gt;  [11,] 25  6.927e-03  56.89000
#&gt;  [12,] 25  7.580e-03  51.84000
#&gt;  [13,] 25  8.291e-03  47.23000
#&gt;  [14,] 25  9.067e-03  43.04000
#&gt;  [15,] 25  9.911e-03  39.21000
#&gt;  [16,] 25  1.083e-02  35.73000
#&gt;  [17,] 25  1.183e-02  32.56000
#&gt;  [18,] 25  1.292e-02  29.66000
#&gt;  [19,] 25  1.410e-02  27.03000
#&gt;  [20,] 25  1.537e-02  24.63000
#&gt;  [21,] 25  1.676e-02  22.44000
#&gt;  [22,] 25  1.823e-02  20.45000
#&gt;  [23,] 25  1.984e-02  18.63000
#&gt;  [24,] 25  2.158e-02  16.98000
#&gt;  [25,] 25  2.345e-02  15.47000
#&gt;  [26,] 25  2.547e-02  14.09000
#&gt;  [27,] 25  2.763e-02  12.84000
#&gt;  [28,] 25  2.995e-02  11.70000
#&gt;  [29,] 25  3.243e-02  10.66000
#&gt;  [30,] 25  3.507e-02   9.71400
#&gt;  [31,] 25  3.788e-02   8.85100
#&gt;  [32,] 25  4.087e-02   8.06500
#&gt;  [33,] 25  4.402e-02   7.34800
#&gt;  [34,] 25  4.736e-02   6.69500
#&gt;  [35,] 25  5.086e-02   6.10100
#&gt;  [36,] 25  5.454e-02   5.55900
#&gt;  [37,] 25  5.838e-02   5.06500
#&gt;  [38,] 25  6.238e-02   4.61500
#&gt;  [39,] 25  6.654e-02   4.20500
#&gt;  [40,] 25  7.083e-02   3.83100
#&gt;  [41,] 25  7.525e-02   3.49100
#&gt;  [42,] 25  7.978e-02   3.18100
#&gt;  [43,] 25  8.440e-02   2.89800
#&gt;  [44,] 25  8.910e-02   2.64100
#&gt;  [45,] 25  9.386e-02   2.40600
#&gt;  [46,] 25  9.866e-02   2.19200
#&gt;  [47,] 25  1.035e-01   1.99800
#&gt;  [48,] 25  1.083e-01   1.82000
#&gt;  [49,] 25  1.130e-01   1.65800
#&gt;  [50,] 25  1.178e-01   1.51100
#&gt;  [51,] 25  1.224e-01   1.37700
#&gt;  [52,] 25  1.270e-01   1.25500
#&gt;  [53,] 25  1.314e-01   1.14300
#&gt;  [54,] 25  1.357e-01   1.04200
#&gt;  [55,] 25  1.399e-01   0.94900
#&gt;  [56,] 25  1.439e-01   0.86470
#&gt;  [57,] 25  1.478e-01   0.78790
#&gt;  [58,] 25  1.515e-01   0.71790
#&gt;  [59,] 25  1.550e-01   0.65410
#&gt;  [60,] 25  1.583e-01   0.59600
#&gt;  [61,] 25  1.614e-01   0.54310
#&gt;  [62,] 25  1.643e-01   0.49480
#&gt;  [63,] 25  1.670e-01   0.45090
#&gt;  [64,] 25  1.696e-01   0.41080
#&gt;  [65,] 25  1.719e-01   0.37430
#&gt;  [66,] 25  1.741e-01   0.34110
#&gt;  [67,] 25  1.761e-01   0.31080
#&gt;  [68,] 25  1.779e-01   0.28320
#&gt;  [69,] 25  1.796e-01   0.25800
#&gt;  [70,] 25  1.811e-01   0.23510
#&gt;  [71,] 25  1.824e-01   0.21420
#&gt;  [72,] 25  1.837e-01   0.19520
#&gt;  [73,] 25  1.848e-01   0.17780
#&gt;  [74,] 25  1.857e-01   0.16200
#&gt;  [75,] 25  1.866e-01   0.14760
#&gt;  [76,] 25  1.874e-01   0.13450
#&gt;  [77,] 25  1.881e-01   0.12260
#&gt;  [78,] 25  1.887e-01   0.11170
#&gt;  [79,] 25  1.892e-01   0.10180
#&gt;  [80,] 25  1.897e-01   0.09272
#&gt;  [81,] 25  1.901e-01   0.08449
#&gt;  [82,] 25  1.904e-01   0.07698
#&gt;  [83,] 25  1.907e-01   0.07014
#&gt;  [84,] 25  1.910e-01   0.06391
#&gt;  [85,] 25  1.912e-01   0.05823
#&gt;  [86,] 25  1.914e-01   0.05306
#&gt;  [87,] 25  1.916e-01   0.04835
#&gt;  [88,] 25  1.917e-01   0.04405
#&gt;  [89,] 25  1.918e-01   0.04014
#&gt;  [90,] 25  1.919e-01   0.03657
#&gt;  [91,] 25  1.920e-01   0.03332
#&gt;  [92,] 25  1.921e-01   0.03036
#&gt;  [93,] 25  1.922e-01   0.02767
#&gt;  [94,] 25  1.922e-01   0.02521
#&gt;  [95,] 25  1.923e-01   0.02297
#&gt;  [96,] 25  1.923e-01   0.02093
#&gt;  [97,] 25  1.923e-01   0.01907
#&gt;  [98,] 25  1.924e-01   0.01737
#&gt;  [99,] 25  1.924e-01   0.01583
#&gt; [100,] 25  1.924e-01   0.01442
#&gt; 
#&gt; $lambda.min
#&gt; [1] 0.0483456
#&gt; 
#&gt; $lambda.1se
#&gt; [1] 0.3743224
#&gt; 
#&gt; attr(,"class")
#&gt; [1] "cv.glmnet"
#&gt; 
#&gt; $en2
#&gt; $lambda
#&gt;   [1] 139.43126157 127.04457259 115.75828292 105.47463612  96.10456016
#&gt;   [6]  87.56689591  79.78769423  72.69957539  66.24114548  60.35646469
#&gt;  [11]  54.99456272  50.10899735  45.65745213  41.60136993  37.90561888
#&gt;  [16]  34.53818818  31.46991073  28.67421060  26.12687276  23.80583340
#&gt;  [21]  21.69098877  19.76402111  18.00823995  16.40843755  14.95075718
#&gt;  [26]  13.62257312  12.41238127  11.30969953  10.30497700   9.38951124
#&gt;  [31]   8.55537294   7.79533719   7.10282092   6.47182589   5.89688671
#&gt;  [36]   5.37302355   4.89569895   4.46077855   4.06449527   3.70341672
#&gt;  [41]   3.37441538   3.07464162   2.80149893   2.55262149   2.32585363
#&gt;  [46]   2.11923121   1.93096455   1.75942298   1.60312069   1.46070387
#&gt;  [51]   1.33093896   1.21270201   1.10496891   1.00680652   0.91736460
#&gt;  [56]   0.83586846   0.76161221   0.69395268   0.63230383   0.57613170
#&gt;  [61]   0.52494975   0.47831466   0.43582251   0.39710524   0.36182750
#&gt;  [66]   0.32968374   0.30039555   0.27370924   0.24939366   0.22723822
#&gt;  [71]   0.20705100   0.18865716   0.17189738   0.15662649   0.14271222
#&gt;  [76]   0.13003406   0.11848219   0.10795656   0.09836600   0.08962744
#&gt;  [81]   0.08166518   0.07441027   0.06779987   0.06177671   0.05628864
#&gt;  [86]   0.05128811   0.04673182   0.04258029   0.03879758   0.03535091
#&gt;  [91]   0.03221043   0.02934894   0.02674166   0.02436601   0.02220140
#&gt;  [96]   0.02022909   0.01843199   0.01679454   0.01530256   0.01394313
#&gt; 
#&gt; $cvm
#&gt;   [1] 1.382423 1.379379 1.378733 1.378311 1.377849 1.377345 1.376793 1.376190
#&gt;   [9] 1.375531 1.374811 1.374026 1.373170 1.372236 1.371218 1.370111 1.368906
#&gt;  [17] 1.367595 1.366173 1.364629 1.362955 1.361152 1.359228 1.357124 1.354853
#&gt;  [25] 1.352409 1.349784 1.346969 1.343957 1.340742 1.337317 1.333677 1.329821
#&gt;  [33] 1.325746 1.321454 1.316947 1.312230 1.307312 1.302203 1.296916 1.291467
#&gt;  [41] 1.285875 1.280162 1.274351 1.268467 1.262538 1.256592 1.250658 1.244767
#&gt;  [49] 1.238946 1.233224 1.227629 1.222186 1.216919 1.211849 1.206995 1.202372
#&gt;  [57] 1.197994 1.193871 1.190009 1.186414 1.183086 1.180024 1.177225 1.174683
#&gt;  [65] 1.172389 1.170336 1.168510 1.166901 1.165496 1.164281 1.163240 1.162361
#&gt;  [73] 1.161629 1.161029 1.160549 1.160174 1.159893 1.159693 1.159563 1.159494
#&gt;  [81] 1.159476 1.159501 1.159560 1.159647 1.159757 1.159883 1.160022 1.160169
#&gt;  [89] 1.160321 1.160475 1.160629 1.160782 1.160932 1.161077 1.161217 1.161351
#&gt;  [97] 1.161479 1.161599 1.161715 1.161777
#&gt; 
#&gt; $cvsd
#&gt;   [1] 0.004834042 0.004909101 0.004897954 0.004902523 0.004907593 0.004913220
#&gt;   [7] 0.004919468 0.004926412 0.004934135 0.004942733 0.004952311 0.004962991
#&gt;  [13] 0.004974909 0.004988219 0.005003096 0.005019735 0.005038357 0.005059212
#&gt;  [19] 0.005082576 0.005108761 0.005138696 0.005170560 0.005207324 0.005248507
#&gt;  [25] 0.005294609 0.005346172 0.005403780 0.005468051 0.005539637 0.005619210
#&gt;  [31] 0.005707459 0.005805078 0.005912750 0.006031135 0.006160854 0.006302473
#&gt;  [37] 0.006456488 0.006623312 0.006803257 0.006996536 0.007203246 0.007423376
#&gt;  [43] 0.007656798 0.007903286 0.008162514 0.008434069 0.008717467 0.009012160
#&gt;  [49] 0.009317552 0.009633007 0.009957859 0.010291417 0.010632970 0.010981788
#&gt;  [55] 0.011337124 0.011698208 0.012064251 0.012434439 0.012807932 0.013183864
#&gt;  [61] 0.013561340 0.013939441 0.014317225 0.014693726 0.015067968 0.015438964
#&gt;  [67] 0.015805716 0.016166964 0.016521821 0.016870088 0.017210480 0.017542182
#&gt;  [73] 0.017864460 0.018176657 0.018478207 0.018768638 0.019047574 0.019314735
#&gt;  [79] 0.019569933 0.019813068 0.020044123 0.020263157 0.020470299 0.020665743
#&gt;  [85] 0.020849703 0.021022652 0.021184752 0.021336313 0.021477949 0.021610000
#&gt;  [91] 0.021732888 0.021847069 0.021953011 0.022051153 0.022141981 0.022225906
#&gt;  [97] 0.022303418 0.022375100 0.022441076 0.022476127
#&gt; 
#&gt; $cvup
#&gt;   [1] 1.387257 1.384289 1.383631 1.383213 1.382757 1.382258 1.381712 1.381116
#&gt;   [9] 1.380465 1.379754 1.378979 1.378133 1.377211 1.376207 1.375114 1.373925
#&gt;  [17] 1.372634 1.371232 1.369711 1.368064 1.366290 1.364399 1.362331 1.360101
#&gt;  [25] 1.357704 1.355130 1.352373 1.349425 1.346281 1.342936 1.339385 1.335626
#&gt;  [33] 1.331659 1.327485 1.323108 1.318533 1.313769 1.308826 1.303719 1.298464
#&gt;  [41] 1.293079 1.287586 1.282008 1.276370 1.270700 1.265026 1.259376 1.253779
#&gt;  [49] 1.248263 1.242857 1.237587 1.232478 1.227552 1.222831 1.218332 1.214071
#&gt;  [57] 1.210058 1.206305 1.202817 1.199598 1.196647 1.193963 1.191542 1.189376
#&gt;  [65] 1.187457 1.185775 1.184316 1.183068 1.182018 1.181151 1.180451 1.179903
#&gt;  [73] 1.179493 1.179206 1.179027 1.178943 1.178940 1.179008 1.179133 1.179308
#&gt;  [81] 1.179521 1.179764 1.180030 1.180313 1.180606 1.180906 1.181207 1.181505
#&gt;  [89] 1.181799 1.182085 1.182362 1.182629 1.182885 1.183128 1.183359 1.183577
#&gt;  [97] 1.183782 1.183974 1.184156 1.184253
#&gt; 
#&gt; $cvlo
#&gt;   [1] 1.377589 1.374470 1.373835 1.373408 1.372942 1.372431 1.371873 1.371263
#&gt;   [9] 1.370597 1.369869 1.369074 1.368207 1.367261 1.366230 1.365108 1.363886
#&gt;  [17] 1.362557 1.361113 1.359546 1.357847 1.356013 1.354057 1.351917 1.349604
#&gt;  [25] 1.347115 1.344438 1.341565 1.338489 1.335202 1.331697 1.327970 1.324016
#&gt;  [33] 1.319834 1.315423 1.310786 1.305928 1.300856 1.295580 1.290113 1.284471
#&gt;  [41] 1.278672 1.272739 1.266694 1.260564 1.254375 1.248158 1.241941 1.235754
#&gt;  [49] 1.229628 1.223591 1.217671 1.211895 1.206286 1.200868 1.195658 1.190674
#&gt;  [57] 1.185930 1.181436 1.177201 1.173230 1.169524 1.166084 1.162908 1.159989
#&gt;  [65] 1.157321 1.154897 1.152705 1.150734 1.148974 1.147410 1.146030 1.144819
#&gt;  [73] 1.143764 1.142852 1.142070 1.141405 1.140845 1.140378 1.139994 1.139681
#&gt;  [81] 1.139432 1.139238 1.139090 1.138981 1.138907 1.138861 1.138837 1.138832
#&gt;  [89] 1.138843 1.138865 1.138896 1.138935 1.138979 1.139026 1.139075 1.139125
#&gt;  [97] 1.139175 1.139224 1.139274 1.139301
#&gt; 
#&gt; $nzero
#&gt;  s0  s1  s2  s3  s4  s5  s6  s7  s8  s9 s10 s11 s12 s13 s14 s15 s16 s17 s18 s19 
#&gt;  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25 
#&gt; s20 s21 s22 s23 s24 s25 s26 s27 s28 s29 s30 s31 s32 s33 s34 s35 s36 s37 s38 s39 
#&gt;  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25 
#&gt; s40 s41 s42 s43 s44 s45 s46 s47 s48 s49 s50 s51 s52 s53 s54 s55 s56 s57 s58 s59 
#&gt;  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25 
#&gt; s60 s61 s62 s63 s64 s65 s66 s67 s68 s69 s70 s71 s72 s73 s74 s75 s76 s77 s78 s79 
#&gt;  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25 
#&gt; s80 s81 s82 s83 s84 s85 s86 s87 s88 s89 s90 s91 s92 s93 s94 s95 s96 s97 s98 s99 
#&gt;  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25  25 
#&gt; 
#&gt; $name
#&gt;            deviance 
#&gt; "Binomial Deviance" 
#&gt; 
#&gt; $glmnet.fit
#&gt; 
#&gt; Call:  glmnet(x = z2[, top2_result], y = y2, family = "binomial", alpha = 0) 
#&gt; 
#&gt;        Df       %Dev    Lambda
#&gt;   [1,] 25 -1.656e-14 139.40000
#&gt;   [2,] 25  2.969e-03 127.00000
#&gt;   [3,] 25  3.255e-03 115.80000
#&gt;   [4,] 25  3.567e-03 105.50000
#&gt;   [5,] 25  3.909e-03  96.10000
#&gt;   [6,] 25  4.282e-03  87.57000
#&gt;   [7,] 25  4.690e-03  79.79000
#&gt;   [8,] 25  5.136e-03  72.70000
#&gt;   [9,] 25  5.624e-03  66.24000
#&gt;  [10,] 25  6.156e-03  60.36000
#&gt;  [11,] 25  6.737e-03  54.99000
#&gt;  [12,] 25  7.371e-03  50.11000
#&gt;  [13,] 25  8.062e-03  45.66000
#&gt;  [14,] 25  8.815e-03  41.60000
#&gt;  [15,] 25  9.635e-03  37.91000
#&gt;  [16,] 25  1.053e-02  34.54000
#&gt;  [17,] 25  1.150e-02  31.47000
#&gt;  [18,] 25  1.255e-02  28.67000
#&gt;  [19,] 25  1.369e-02  26.13000
#&gt;  [20,] 25  1.493e-02  23.81000
#&gt;  [21,] 25  1.628e-02  21.69000
#&gt;  [22,] 25  1.769e-02  19.76000
#&gt;  [23,] 25  1.926e-02  18.01000
#&gt;  [24,] 25  2.094e-02  16.41000
#&gt;  [25,] 25  2.275e-02  14.95000
#&gt;  [26,] 25  2.470e-02  13.62000
#&gt;  [27,] 25  2.679e-02  12.41000
#&gt;  [28,] 25  2.903e-02  11.31000
#&gt;  [29,] 25  3.142e-02  10.30000
#&gt;  [30,] 25  3.396e-02   9.39000
#&gt;  [31,] 25  3.667e-02   8.55500
#&gt;  [32,] 25  3.954e-02   7.79500
#&gt;  [33,] 25  4.258e-02   7.10300
#&gt;  [34,] 25  4.577e-02   6.47200
#&gt;  [35,] 25  4.914e-02   5.89700
#&gt;  [36,] 25  5.266e-02   5.37300
#&gt;  [37,] 25  5.633e-02   4.89600
#&gt;  [38,] 25  6.016e-02   4.46100
#&gt;  [39,] 25  6.412e-02   4.06400
#&gt;  [40,] 25  6.820e-02   3.70300
#&gt;  [41,] 25  7.240e-02   3.37400
#&gt;  [42,] 25  7.670e-02   3.07500
#&gt;  [43,] 25  8.109e-02   2.80100
#&gt;  [44,] 25  8.553e-02   2.55300
#&gt;  [45,] 25  9.002e-02   2.32600
#&gt;  [46,] 25  9.453e-02   2.11900
#&gt;  [47,] 25  9.905e-02   1.93100
#&gt;  [48,] 25  1.035e-01   1.75900
#&gt;  [49,] 25  1.080e-01   1.60300
#&gt;  [50,] 25  1.124e-01   1.46100
#&gt;  [51,] 25  1.167e-01   1.33100
#&gt;  [52,] 25  1.210e-01   1.21300
#&gt;  [53,] 25  1.251e-01   1.10500
#&gt;  [54,] 25  1.290e-01   1.00700
#&gt;  [55,] 25  1.329e-01   0.91740
#&gt;  [56,] 25  1.366e-01   0.83590
#&gt;  [57,] 25  1.401e-01   0.76160
#&gt;  [58,] 25  1.434e-01   0.69400
#&gt;  [59,] 25  1.466e-01   0.63230
#&gt;  [60,] 25  1.495e-01   0.57610
#&gt;  [61,] 25  1.523e-01   0.52490
#&gt;  [62,] 25  1.549e-01   0.47830
#&gt;  [63,] 25  1.574e-01   0.43580
#&gt;  [64,] 25  1.596e-01   0.39710
#&gt;  [65,] 25  1.617e-01   0.36180
#&gt;  [66,] 25  1.636e-01   0.32970
#&gt;  [67,] 25  1.653e-01   0.30040
#&gt;  [68,] 25  1.669e-01   0.27370
#&gt;  [69,] 25  1.683e-01   0.24940
#&gt;  [70,] 25  1.696e-01   0.22720
#&gt;  [71,] 25  1.708e-01   0.20710
#&gt;  [72,] 25  1.718e-01   0.18870
#&gt;  [73,] 25  1.727e-01   0.17190
#&gt;  [74,] 25  1.735e-01   0.15660
#&gt;  [75,] 25  1.743e-01   0.14270
#&gt;  [76,] 25  1.749e-01   0.13000
#&gt;  [77,] 25  1.755e-01   0.11850
#&gt;  [78,] 25  1.760e-01   0.10800
#&gt;  [79,] 25  1.764e-01   0.09837
#&gt;  [80,] 25  1.768e-01   0.08963
#&gt;  [81,] 25  1.771e-01   0.08167
#&gt;  [82,] 25  1.774e-01   0.07441
#&gt;  [83,] 25  1.776e-01   0.06780
#&gt;  [84,] 25  1.778e-01   0.06178
#&gt;  [85,] 25  1.780e-01   0.05629
#&gt;  [86,] 25  1.782e-01   0.05129
#&gt;  [87,] 25  1.783e-01   0.04673
#&gt;  [88,] 25  1.784e-01   0.04258
#&gt;  [89,] 25  1.785e-01   0.03880
#&gt;  [90,] 25  1.786e-01   0.03535
#&gt;  [91,] 25  1.787e-01   0.03221
#&gt;  [92,] 25  1.787e-01   0.02935
#&gt;  [93,] 25  1.788e-01   0.02674
#&gt;  [94,] 25  1.788e-01   0.02437
#&gt;  [95,] 25  1.788e-01   0.02220
#&gt;  [96,] 25  1.789e-01   0.02023
#&gt;  [97,] 25  1.789e-01   0.01843
#&gt;  [98,] 25  1.789e-01   0.01679
#&gt;  [99,] 25  1.789e-01   0.01530
#&gt; [100,] 25  1.790e-01   0.01394
#&gt; 
#&gt; $lambda.min
#&gt; [1] 0.08166518
#&gt; 
#&gt; $lambda.1se
#&gt; [1] 0.4358225
#&gt; 
#&gt; attr(,"class")
#&gt; [1] "cv.glmnet"
#&gt; 
#&gt; $feature
#&gt;  [1] "X1--X2"  "X1--X3"  "X1--X4"  "X1--X5"  "X1--X6"  "X1--X7"  "X1--X8" 
#&gt;  [8] "X1--X9"  "X1--X10" "X2--X3"  "X2--X4"  "X2--X5"  "X2--X6"  "X2--X7" 
#&gt; [15] "X2--X8"  "X2--X9"  "X2--X10" "X3--X4"  "X3--X6"  "X3--X7"  "X3--X9" 
#&gt; [22] "X3--X10" "X4--X6"  "X6--X9"  "X9--X10"
#&gt; </div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Kevin Wang.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
   </div>

  

  </body>
</html>

